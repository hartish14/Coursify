<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>API Tool</title>
</head>
<body>
    <h3>Complexity Summary</h3>
    <p>
        If I have to take the game from him, the fastest way is to take a hard disk, copy it, and bring it. I will take my bike and bring the game by bike, and I will enjoy the game and satisfy my soul.

Algorithm 1 takes 250kb input, algorithm 2 takes 60 GB input, and so on. The runtime of the algorithms keeps on changing as the size of the input increases.

If I send 250 kb, it will arrive in 2 sec, and if I send 1 MB, it will arrive in 4 sec.

If the file is 250 kb, it will take 1 sec to send, if it is 1MB, 4 secs.</p>

<p>The runtime of algo2 remained the same as the input size increased, because the copying time was negligible. Therefore, the runtime of algo2 changed only along with input size, and not along with input time.

When we analyze algorithms, we ask questions like as the input will increase, Then the runtime will change as per what? And if there is another algorithm that performs better, then we use that one.

Analysis Time complexity analysis asks what effect the algorithm has on runtime as the size of the input keeps on increasing.

You have to make a formula to tell me if overall I need time in algo 1 if I say algo 1 time ok.</p>

<p>You need to change clothes, get ready, make hair, and go to aunty's house in K1 time. After that, you will go to his father's house and get treated, and Aunty will make some tea and all in K3 time.

Consider different routes to come and go. If the size of the input is n, the time it takes to bring the data depends on the size of the input.

We are doing a real-world analysis of things. If I write in n terms, time taken by algo 1 is equal to algo 2, and algo 2 is a physical visit, then algo 2 does not depend on algo 1.

Why complicate things when we can write n to power 0 as 1. This is Big O of 1, which runs in constant time.

If we do an analysis of the first algorithm, then we have to declare it constant. Now, consider your internet speed is L2 Kbps, so your main time is required in that.

If the game is N kb, then you will need n/L2. Speed = distance /time.</p>

<p>Here we can consider 1/L2 as another constant, and we will write it like this: L1 n0+ L2' n1. Now tell us which is the most impactful term in these both?

Compared to this term, n to the power 1 has a larger impact, so I picked it over here.

If you go into the real world, you won't listen to a story. Instead, you will be told a Big O of n to the power 1 algorithm that runs in linear time.

You can send a file by internet or can physically go and copy in hard disk. The time required will be dependent on the size of the file.

Big O analysis tells you that the time required to run your algorithm scales according to what? If it runs in linear time, Big O of n, if it runs in constant time, Big O of 1.

A reverse hand fingers is a good kid, but it won't fall. We will understand what is Big O.</p>

<p>The mathematical definition of Big O is one, and the industrial definition is another. You have to precisely tell what is Big O.

In the industry, O means the order of and its mathematical definition that I will tell you. If you are giving exams like GATE, you can watch this course for GATE as well.

When I use Big O's mathematical definition, I will say Big O, but when I give industry definition, I will say an order of.

When you wanted to send 250 kb, the graph of Big O of n shows that you needed less time than the graph of x=1 because you were sending it through the internet.

As input size increases, you will have a benefit in Big O of 1, but you won't want to wait for so much time.

In that case, you require less time. This graph shows the Big O of 1 and Big O of n algorithms equations.</p>

<p>We will compare the graphs of the algorithm runtime and I will show you other graphs. Let's see some concepts from the notes that I have made for you all.

I have prepared notes for you all, you must be knowing the Ds0 pdf, and the Ds1.pdf I have said 0 to the introduction so it is Ds0 pdf. I am giving you an example of time complexity.

Two developers want to sort n numbers, so they increase the size of the input, and the time taken to execute the algorithm increases or decreases.

After 110 elements, Shubham's algorithm took 180ms, Rohan's algorithm was around 120-130ms, and Rohan's algorithm did it in 800 ms. So if we have to use for less elements, Shubham's algorithm is better, but if we have to run for big elements, Rohan's algorithm is better.

The highest order term of this equation gives a big impact on the formula, and if you add a big value of n, then this will be nothing in comparison to as big as this will be.

After taking the highest order term, we will add Big O and write the equation. Then we will take the highest degree term.

30:31 Ok, these are the formulas. 30:37 I visualized it for you guys, and here I showed you guys that you can plot Big O of 1 and Big O of 1 in a graph.

If you read notes along with the video, then you won't have a problem understanding time complexity of Big O.
    </p>
</body>
</html>